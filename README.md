# ğŸ›¡ï¸ LLM-Based Inappropriate Language Detection in User Reviews

This project replicates **Yelpâ€™s AI moderation pipeline** using **OpenAIâ€™s GPT-4** to detect and flag inappropriate content in user reviews, including:

- Profanity and offensive language  
- Sarcasm or metaphor with toxic meaning  
- Implicit hate speech or discrimination  
- Sexual innuendos and indirect threats  
- Harassment, personal attacks, and lewd comments

---

## ğŸ“Œ Features

âœ… Real-time classification using OpenAI GPT  
âœ… Detects nuanced and indirect content  
âœ… Easy to extend for other platforms (e.g., social media, forums)  
âœ… Uses the latest OpenAI Python SDK (`>=1.0.0`)

---

## ğŸš€ Quickstart

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/inappropriate-language-detector.git
cd inappropriate-language-detector
```

### 2. Install dependencies
```bash
pip install -r requirements.txt
```

### 3. Set your OpenAI API key
```bash
export OPENAI_API_KEY=your_key_here  # for Linux/macOS
set OPENAI_API_KEY=your_key_here     # for Windows CMD
```

### 4. Run the script
```bash
python Yelp-s-AI-Pipeline-for-Inappropriate-Language-Detection-in-User-Reviews-Background.py
```

### ğŸ§ª Example Test Reviews
The model can detect:

## Explicit Profanity:
â€œThe waiter was a f***ing moron.â€

## Sarcastic or Metaphorical Abuse:
â€œIf rudeness were a sport, theyâ€™d win gold.â€

## Implicit Hate/Discrimination:
â€œThey treated us differently â€” not the right color, I guess.â€

## Sexual Innuendos & Threats:
â€œThat manager really knew how to stroke a bottle.â€


### ğŸ“Š Future Improvements
Add confidence scores or explanations

Fine-tune on custom moderation dataset

Build FastAPI or Streamlit UI for moderation dashboard

### ğŸ™Œ Credits
Inspired by Yelpâ€™s AI moderation system and OpenAIâ€™s GPT capabilities.

Built with ğŸ’¬ by **Anurag Pathak**
